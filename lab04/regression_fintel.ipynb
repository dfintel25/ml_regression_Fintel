{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic Data Analysis\n",
    "**Author:** Derek Fintel\n",
    "\n",
    "**Date:** April, 04th, 2025 \n",
    "\n",
    "**Objective:** Predicting a Continuous Target with Regression.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "In this project we utilize a trusted Titanic dataset to conduct various analyses, exercise functions, and provide meaningful predicitions of target data. \n",
    "\n",
    "This project is organized into the following Sections:\n",
    "- Section 0: Imports\n",
    "- Section 1: Load and Inspect the Data\n",
    "- Section 2: Data Exploration and Preparation\n",
    "- Section 3: Feature Selection and Justification\n",
    "- Section 4: Train a Regression Model (Linear Regression)\n",
    "- Section 5: Compare Alternative Models\n",
    "- Section 6: Final Thoughts & Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports  \n",
    "Below are our modules used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, ElasticNet\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1. Load and Inspect the Data\n",
    "\n",
    "### 1.1 Load the dataset and display its info\n",
    "1.1 Load the dataset and display the first 10 rows.\n",
    "1.2 Check for missing values and display summary statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 15 columns):\n",
      " #   Column       Non-Null Count  Dtype   \n",
      "---  ------       --------------  -----   \n",
      " 0   survived     891 non-null    int64   \n",
      " 1   pclass       891 non-null    int64   \n",
      " 2   sex          891 non-null    object  \n",
      " 3   age          714 non-null    float64 \n",
      " 4   sibsp        891 non-null    int64   \n",
      " 5   parch        891 non-null    int64   \n",
      " 6   fare         891 non-null    float64 \n",
      " 7   embarked     889 non-null    object  \n",
      " 8   class        891 non-null    category\n",
      " 9   who          891 non-null    object  \n",
      " 10  adult_male   891 non-null    bool    \n",
      " 11  deck         203 non-null    category\n",
      " 12  embark_town  889 non-null    object  \n",
      " 13  alive        891 non-null    object  \n",
      " 14  alone        891 non-null    bool    \n",
      "dtypes: bool(2), category(2), float64(2), int64(4), object(5)\n",
      "memory usage: 80.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# We Load the 'titantic' dataset via sns.load_dataset\n",
    "titanic = sns.load_dataset('titanic')\n",
    "\n",
    "#We retrieve its summary info via '.info()'\n",
    "titanic.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2218892b",
   "metadata": {},
   "source": [
    "### 1.2 Display the first 10 rows.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "16ce92fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   survived  pclass     sex   age  sibsp  parch     fare embarked   class  \\\n",
      "0         0       3    male  22.0      1      0   7.2500        S   Third   \n",
      "1         1       1  female  38.0      1      0  71.2833        C   First   \n",
      "2         1       3  female  26.0      0      0   7.9250        S   Third   \n",
      "3         1       1  female  35.0      1      0  53.1000        S   First   \n",
      "4         0       3    male  35.0      0      0   8.0500        S   Third   \n",
      "5         0       3    male   NaN      0      0   8.4583        Q   Third   \n",
      "6         0       1    male  54.0      0      0  51.8625        S   First   \n",
      "7         0       3    male   2.0      3      1  21.0750        S   Third   \n",
      "8         1       3  female  27.0      0      2  11.1333        S   Third   \n",
      "9         1       2  female  14.0      1      0  30.0708        C  Second   \n",
      "\n",
      "     who  adult_male deck  embark_town alive  alone  \n",
      "0    man        True  NaN  Southampton    no  False  \n",
      "1  woman       False    C    Cherbourg   yes  False  \n",
      "2  woman       False  NaN  Southampton   yes   True  \n",
      "3  woman       False    C  Southampton   yes  False  \n",
      "4    man        True  NaN  Southampton    no   True  \n",
      "5    man        True  NaN   Queenstown    no   True  \n",
      "6    man        True    E  Southampton    no   True  \n",
      "7  child       False  NaN  Southampton    no  False  \n",
      "8  woman       False  NaN  Southampton   yes  False  \n",
      "9  child       False  NaN    Cherbourg   yes  False  \n"
     ]
    }
   ],
   "source": [
    "# Here we 'print' the first 10 rows via '.head(10)'\n",
    "print(titanic.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a148e8f6",
   "metadata": {},
   "source": [
    "### Reflection 1: What do you notice about the dataset? Are there any data issues?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2. Data Exploration and Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc9e869",
   "metadata": {},
   "source": [
    "### 2.1 Explore Data Patterns and Distributions\n",
    "Prepare the Titanic data for regression modeling. See the previous work.\n",
    "\n",
    "Create histograms, boxplots, and count plots for categorical variables (as applicable).\n",
    "Identify patterns, outliers, and anomalies in feature distributions.\n",
    "Check for class imbalance in the target variable (as applicable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   survived  pclass  sex   age  sibsp  parch     fare  class    who  \\\n",
      "0         0       3    0  22.0      1      0   7.2500  Third    man   \n",
      "1         1       1    1  38.0      1      0  71.2833  First  woman   \n",
      "2         1       3    1  26.0      0      0   7.9250  Third  woman   \n",
      "3         1       1    1  35.0      1      0  53.1000  First  woman   \n",
      "4         0       3    0  35.0      0      0   8.0500  Third    man   \n",
      "\n",
      "   adult_male deck  embark_town alive  alone  family_size  embarked_Q  \\\n",
      "0        True  NaN  Southampton    no  False            2       False   \n",
      "1       False    C    Cherbourg   yes  False            2       False   \n",
      "2       False  NaN  Southampton   yes   True            1       False   \n",
      "3       False    C  Southampton   yes  False            2       False   \n",
      "4        True  NaN  Southampton    no   True            1       False   \n",
      "\n",
      "   embarked_S  \n",
      "0        True  \n",
      "1       False  \n",
      "2        True  \n",
      "3        True  \n",
      "4        True  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\derek\\AppData\\Local\\Temp\\ipykernel_3716\\770190317.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  titanic['age'].fillna(titanic['age'].median(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# 1. Impute missing 'Age' values using median\n",
    "titanic['age'].fillna(titanic['age'].median(), inplace=True)\n",
    "\n",
    "# 2. Drop rows with missing 'fare' (or impute if preferred)\n",
    "titanic.dropna(subset=['fare'], inplace=True)\n",
    "\n",
    "# Alternatively, you can impute fare instead of dropping:\n",
    "# titanic['fare'].fillna(titanic['fare'].median(), inplace=True)\n",
    "\n",
    "# 3. Create 'family_size' feature\n",
    "titanic['family_size'] = titanic['sibsp'] + titanic['parch'] + 1\n",
    "\n",
    "# 4. Optional: Convert categorical features to numeric\n",
    "\n",
    "# Convert 'sex' to binary\n",
    "titanic['sex'] = titanic['sex'].map({'male': 0, 'female': 1})\n",
    "\n",
    "# One-hot encode 'embarked' (drop_first avoids multicollinearity)\n",
    "titanic = pd.get_dummies(titanic, columns=['embarked'], drop_first=True)\n",
    "\n",
    "# Preview the cleaned data\n",
    "print(titanic.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd864d57",
   "metadata": {},
   "source": [
    "### 2.2 Handle missing values and clean data\n",
    "Impute or drop missing values (as applicable).\n",
    "Remove or transform outliers (as applicable).\n",
    "Convert categorical data to numerical format using encoding (as applicable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cfe9bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ff49290",
   "metadata": {},
   "source": [
    "### 2.3 Feature selection and engineering\n",
    "Create new features (as applicable).\n",
    "Transform or combine existing features to improve model performance (as applicable).\n",
    "Scale or normalize data (as applicable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35187e60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4ac6fa13",
   "metadata": {},
   "source": [
    "### Reflection 2: \n",
    "What patterns or anomalies do you see? Do any features stand out? What preprocessing steps were necessary to clean and improve the data? Did you create or modify any features to improve performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3. Feature Selection and Justification\n",
    "### 3.1 Choose features and target\n",
    "Select two or more input features (numerical for regression, numerical and/or categorical for classification)\n",
    "Select a target variable (as applicable)\n",
    "Regression: Continuous target variable (e.g., price, temperature).\n",
    "Classification: Categorical target variable (e.g., gender, species).\n",
    "Clustering: No target variable.\n",
    "Justify your selection with reasoning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "d022a37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case 1. age\n",
    "X1 = titanic[['age']]\n",
    "y1 = titanic['fare']\n",
    "# Case 2. family_size\n",
    "X2 = titanic[['family_size']]\n",
    "y2 = titanic['fare']\n",
    "# Case 3. age, family_size\n",
    "X3 = titanic[['age', 'family_size']]\n",
    "y3 = titanic['fare']\n",
    "# Case 4. parch\n",
    "X4 = titanic[['parch']]\n",
    "y4 = titanic['fare']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50c2aa7",
   "metadata": {},
   "source": [
    "### 3.2 Define X and y\n",
    "Assign input features to X\n",
    "Assign target variable to y (as applicable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416ee629",
   "metadata": {},
   "source": [
    "### Reflection of Section 3:\n",
    "\n",
    "Reflection 3: Why did you choose these features? How might they impact predictions or accuracy? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4. Train a Regression Model (Linear Regression)\n",
    "\n",
    "### 4.1 Split the Data\n",
    "Split the data into training and test sets using train_test_split (or StratifiedShuffleSplit if class imbalance is an issue)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "e1b27c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Case 1\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.2, random_state=123)\n",
    "# Train Case 2\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.2, random_state=123)\n",
    "# Train Case 3\n",
    "X3_train, X3_test, y3_train, y3_test = train_test_split(X3, y3, test_size=0.2, random_state=123)\n",
    "# Train Case 4\n",
    "X4_train, X4_test, y4_train, y4_test = train_test_split(X4, y4, test_size=0.2, random_state=123)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffca86eb",
   "metadata": {},
   "source": [
    "### 4.2 Train model using Scikit-Learn model.fit() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "23199b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression for Case 1\n",
    "lr_model1 = LinearRegression().fit(X1_train, y1_train)\n",
    "# Linear Regression for Case 2\n",
    "lr_model2 = LinearRegression().fit(X2_train, y2_train)\n",
    "# Linear Regression for Case 3\n",
    "lr_model3 = LinearRegression().fit(X3_train, y3_train)\n",
    "# Linear Regression for Case 4\n",
    "lr_model4 = LinearRegression().fit(X4_train, y4_train)\n",
    "\n",
    "# Predictions\n",
    "# Case 1\n",
    "y_pred_train1 = lr_model1.predict(X1_train)\n",
    "y_pred_test1 = lr_model1.predict(X1_test)\n",
    "# Case 2\n",
    "y_pred_train2 = lr_model2.predict(X2_train)\n",
    "y_pred_test2 = lr_model2.predict(X2_test)\n",
    "# Predictions for Case 3\n",
    "y_pred_train3 = lr_model3.predict(X3_train)\n",
    "y_pred_test3 = lr_model3.predict(X3_test)\n",
    "# Predictions for Case 4\n",
    "y_pred_train4 = lr_model4.predict(X4_train)\n",
    "y_pred_test4 = lr_model4.predict(X4_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85af3d24",
   "metadata": {},
   "source": [
    "### 4.3 Evalulate performance, for example:\n",
    "Regression: R^2, MAE, RMSE (RMSE has been recently updated)\n",
    "Classification: Accuracy, Precision, Recall, F1-score, Confusion Matrix\n",
    "Clustering: Inertia, Silhouette Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "844440cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case 1: Training R²: 0.009950688019452314\n",
      "Case 1: Test R²: 0.0034163395508415295\n",
      "Case 1: Test RMSE: 37.97164180172938\n",
      "Case 1: Test MAE: 25.28637293162364\n",
      "\n",
      "Case 2: Training R²: 0.049915792364760736\n",
      "Case 2: Test R²: 0.022231186110131973\n",
      "Case 2: Test RMSE: 37.6114940041967\n",
      "Case 2: Test MAE: 25.02534815941641\n",
      "\n",
      "Case 3: Training R²: 0.07347466201590014\n",
      "Case 3: Test R²: 0.049784832763073106\n",
      "Case 3: Test RMSE: 37.0777586646559\n",
      "Case 3: Test MAE: 24.284935030470688\n",
      "\n",
      "Case 4: Training R²: 0.051165530832692374\n",
      "Case 4: Test R²: 0.0030800228833659515\n",
      "Case 4: Test RMSE: 37.97804839823722\n",
      "Case 4: Test MAE: 25.156643237188245\n"
     ]
    }
   ],
   "source": [
    "# Evaluation for Case 1\n",
    "print(\"Case 1: Training R²:\", r2_score(y1_train, y_pred_train1))\n",
    "print(\"Case 1: Test R²:\", r2_score(y1_test, y_pred_test1))\n",
    "print(\"Case 1: Test RMSE:\", mean_squared_error(y1_test, y_pred_test1) ** 0.5)\n",
    "print(\"Case 1: Test MAE:\", mean_absolute_error(y1_test, y_pred_test1))\n",
    "# Evaluation for Case 2\n",
    "print(\"\\nCase 2: Training R²:\", r2_score(y2_train, y_pred_train2))\n",
    "print(\"Case 2: Test R²:\", r2_score(y2_test, y_pred_test2))\n",
    "print(\"Case 2: Test RMSE:\", mean_squared_error(y2_test, y_pred_test2) ** 0.5)\n",
    "print(\"Case 2: Test MAE:\", mean_absolute_error(y2_test, y_pred_test2))\n",
    "# Evaluation for Case 3\n",
    "print(\"\\nCase 3: Training R²:\", r2_score(y3_train, y_pred_train3))\n",
    "print(\"Case 3: Test R²:\", r2_score(y3_test, y_pred_test3))\n",
    "print(\"Case 3: Test RMSE:\", mean_squared_error(y3_test, y_pred_test3) ** 0.5)\n",
    "print(\"Case 3: Test MAE:\", mean_absolute_error(y3_test, y_pred_test3))\n",
    "# Evaluation for Case 4\n",
    "print(\"\\nCase 4: Training R²:\", r2_score(y4_train, y_pred_train4))\n",
    "print(\"Case 4: Test R²:\", r2_score(y4_test, y_pred_test4))\n",
    "print(\"Case 4: Test RMSE:\", mean_squared_error(y4_test, y_pred_test4) ** 0.5)\n",
    "print(\"Case 4: Test MAE:\", mean_absolute_error(y4_test, y_pred_test4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflection 4: How well did the model perform? Any surprises in the results?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282e48ce",
   "metadata": {},
   "source": [
    "### Section 5. Improve the Model or Try Alternates (Implement Pipelines)\n",
    "5.1 Implement Pipeline 1: Imputer → StandardScaler → Linear Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "322f160c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression - MSE: 1524.637, R²: 0.015\n",
      "Lasso Regression - MSE: 1524.643, R²: 0.015\n",
      "ElasticNet Regression - MSE: 1524.641, R²: 0.015\n",
      "\n",
      "Ridge Results:\n",
      "MSE: 1524.637\n",
      "R²: 0.015\n",
      "Coefficients: [0.36204943]\n",
      "\n",
      "Lasso Results:\n",
      "MSE: 1524.643\n",
      "R²: 0.015\n",
      "Coefficients: [0.36146061]\n",
      "\n",
      "ElasticNet Results:\n",
      "MSE: 1524.641\n",
      "R²: 0.015\n",
      "Coefficients: [0.36164951]\n"
     ]
    }
   ],
   "source": [
    "# Assuming Case 1 (Age) as the best case for regression\n",
    "X = titanic[['age']]\n",
    "y = titanic['fare']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Dictionary to store models and results\n",
    "models = {\n",
    "    \"Ridge\": Ridge(alpha=1.0),\n",
    "    \"Lasso\": Lasso(alpha=0.1),\n",
    "    \"ElasticNet\": ElasticNet(alpha=0.1, l1_ratio=0.5)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    results[name] = {\n",
    "        \"MSE\": mse,\n",
    "        \"R²\": r2,\n",
    "        \"Coefficients\": model.coef_\n",
    "    }\n",
    "    print(f\"{name} Regression - MSE: {mse:.3f}, R²: {r2:.3f}\")\n",
    "\n",
    "# You can check the results for each model\n",
    "for name, result in results.items():\n",
    "    print(f\"\\n{name} Results:\")\n",
    "    print(f\"MSE: {result['MSE']:.3f}\")\n",
    "    print(f\"R²: {result['R²']:.3f}\")\n",
    "    print(f\"Coefficients: {result['Coefficients']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fb5dad",
   "metadata": {},
   "source": [
    "### 5.2 Elastic Net (L1 + L2 combined)\n",
    "5.2 Implement Pipeline 2: Imputer → Polynomial Features (degree=3) → StandardScaler → Linear Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "18e55163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elastic Net - MSE: 2282.922, R²: 0.074\n",
      "Elastic Net Coefficients: [6.33426796 6.86793796 5.48097229]\n"
     ]
    }
   ],
   "source": [
    "# Assuming you want to use 'age', 'family_size', and 'parch' for the ElasticNet model\n",
    "X = titanic[['age', 'family_size', 'parch']]\n",
    "y = titanic['fare']\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train ElasticNet with scaled features\n",
    "elastic_model = ElasticNet(alpha=0.3, l1_ratio=0.5, random_state=42)\n",
    "elastic_model.fit(X_scaled, y)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_elastic = elastic_model.predict(X_scaled)\n",
    "mse_elastic = mean_squared_error(y, y_pred_elastic)\n",
    "r2_elastic = r2_score(y, y_pred_elastic)\n",
    "\n",
    "print(f\"Elastic Net - MSE: {mse_elastic:.3f}, R²: {r2_elastic:.3f}\")\n",
    "print(f\"Elastic Net Coefficients: {elastic_model.coef_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "84943b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "elastic_model = ElasticNet(alpha=0.3, l1_ratio=0.5)\n",
    "elastic_model.fit(X1_train, y1_train)\n",
    "y_pred_elastic = elastic_model.predict(X1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e9eae3",
   "metadata": {},
   "source": [
    "### 5.3 Compare performance of all models across the same performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "afce0b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polynomial Regression - MSE: 1451.569, R²: -0.003\n"
     ]
    }
   ],
   "source": [
    "# Set up the poly inputs\n",
    "poly = PolynomialFeatures(degree=3)\n",
    "X_train_poly = poly.fit_transform(X1_train)\n",
    "X_test_poly = poly.transform(X1_test)\n",
    "\n",
    "# Use the poly inputs in the LR model\n",
    "poly_model = LinearRegression()\n",
    "poly_model.fit(X_train_poly, y1_train)\n",
    "y_pred_poly = poly_model.predict(X_test_poly)\n",
    "\n",
    "# Use the correct variable name for predictions\n",
    "y_pred_poly = poly_model.predict(X_test_poly)\n",
    "\n",
    "# Evaluate the Polynomial Regression model\n",
    "mse_poly = mean_squared_error(y1_test, y_pred_poly)\n",
    "r2_poly = r2_score(y1_test, y_pred_poly)\n",
    "\n",
    "print(f\"Polynomial Regression - MSE: {mse_poly:.3f}, R²: {r2_poly:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78a6aac",
   "metadata": {},
   "source": [
    "### Reflection 5: \n",
    "Which models performed better? How does scaling impact results?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da5716d",
   "metadata": {},
   "source": [
    "### Section 6. Final Thoughts & Insights\n",
    "Your notebook should tell a data story. Use this section to demonstrate your thinking and value as an analyst.\n",
    "\n",
    "### 6.1 Summarize Findings\n",
    "1) What features were most useful? \n",
    "   1) Ans: Sex and Age were helpful base parameters.\n",
    "2) What regression model performed best? \n",
    "   1) Ans: Poly appeared to smoothen everything out. \n",
    "3) How did model complexity or regularization affect results?\n",
    "   1) Ans: Increasing the polynomial degree helped sharpen the plotting/insights. \n",
    "\n",
    "### 6.2 Discuss Challenges\n",
    "1) Was fare hard to predict? Why?\n",
    "   1) Ans: It was as the selected inputs did not reveal strong correlations to 'fare'.\n",
    "2) Did skew or outliers impact the models?\n",
    "   1) Ans: Yes, and particularly around how 'fare' data may have been affected/influenced.  \n",
    "\n",
    "### 6.3 If you had more time, what would you try next?\n",
    "\n",
    "Reflection 6: What did you learn from this project?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
